# -*- coding: utf-8 -*-
"""English_Audio_to_Hindi_ French(task5&6).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18_yNCYe8Z6iXr7s7_Y2khOiEHuMOTK4w
"""

!pip install gradio SpeechRecognition transformers

import datetime
import pytz
import speech_recognition as sr
from transformers import MarianMTModel, MarianTokenizer
import gradio as gr

model_name_hi = 'Helsinki-NLP/opus-mt-en-hi'
tokenizer_hi = MarianTokenizer.from_pretrained(model_name_hi)
model_hi = MarianMTModel.from_pretrained(model_name_hi)

model_name_fr = 'Helsinki-NLP/opus-mt-en-fr'
tokenizer_fr = MarianTokenizer.from_pretrained(model_name_fr)
model_fr = MarianMTModel.from_pretrained(model_name_fr)

def is_after_6pm():
    ist = pytz.timezone('Asia/Kolkata')
    now = datetime.datetime.now(ist)
    return now.hour >= 18

def is_between_9_and_10_pm():
    ist = pytz.timezone('Asia/Kolkata')
    now = datetime.datetime.now(ist)
    return now.hour == 21

def translate_audio_to_hindi(audio):
    recognizer = sr.Recognizer()

    with sr.AudioFile(audio) as source:
        audio_data = recognizer.record(source)
        try:
            transcript = recognizer.recognize_google(audio_data)
            words = transcript.split()

            if any(word[0].lower() in 'aeiou' for word in words) and not is_after_6pm():
                return "Translation is restricted for words starting with vowels before 6 PM."

            inputs_hi = tokenizer_hi(transcript, return_tensors="pt", padding=True)
            translated_tokens_hi = model_hi.generate(**inputs_hi)
            hindi_translation = tokenizer_hi.decode(translated_tokens_hi[0], skip_special_tokens=True)
            return f"Translated to Hindi: {hindi_translation}"
        except sr.UnknownValueError:
            return "Sorry, I could not understand the audio."
        except sr.RequestError as e:
            return f"Error with Speech Recognition: {e}"

def translate_audio_to_hindi_and_french(audio):
    recognizer = sr.Recognizer()

    with sr.AudioFile(audio) as source:
        audio_data = recognizer.record(source)
        try:
            transcript = recognizer.recognize_google(audio_data)
            words = transcript.split()

            if any(word[0].lower() in 'aeiou' for word in words) and not is_between_9_and_10_pm():
                return "Translation is restricted for words starting with vowels outside 9 PM to 10 PM."

            inputs_hi = tokenizer_hi(transcript, return_tensors="pt", padding=True)
            translated_tokens_hi = model_hi.generate(**inputs_hi)
            hindi_translation = tokenizer_hi.decode(translated_tokens_hi[0], skip_special_tokens=True)

            inputs_fr = tokenizer_fr(transcript, return_tensors="pt", padding=True)
            translated_tokens_fr = model_fr.generate(**inputs_fr)
            french_translation = tokenizer_fr.decode(translated_tokens_fr[0], skip_special_tokens=True)

            return f"Translated to Hindi: {hindi_translation}\nTranslated to French: {french_translation}"
        except sr.UnknownValueError:
            return "Sorry, I could not understand the audio."
        except sr.RequestError as e:
            return f"Error with Speech Recognition: {e}"


interface_hi = gr.Interface(
    fn=translate_audio_to_hindi,
    inputs=gr.Audio(type="filepath", label="Record English Audio"),
    outputs="text",
    title="English Audio to Hindi Translation",
    description="Record English audio and get its translation to Hindi."
)


interface_both = gr.Interface(
    fn=translate_audio_to_hindi_and_french,
    inputs=gr.Audio(type="filepath", label="Record English Audio"),
    outputs="text",
    title="English Audio to Hindi and French Translation",
    description="Record English audio and get its translations to Hindi and French."
)

interface_hi.launch()
interface_both.launch()

